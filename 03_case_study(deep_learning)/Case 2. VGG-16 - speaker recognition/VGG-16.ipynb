{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of DATA\n",
    "\n",
    "Description of Data\n",
    "In this script, Pannous uses data from the following link: http://pannous.net/files/spoken_numbers_pcm.tar\n",
    "\n",
    "This tar file contains 15 different speakers, each saying 10 different phrases, each phrase sampled at 16 different frequencies.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pip install librosa ; if you want mfcc_batch_generator\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "#!/usr/local/bin/python\n",
    "#!/usr/bin/env PYTHONIOENCODING=\"utf-8\" python\n",
    "import os\n",
    "\n",
    "import tflearn\n",
    "import speech_data as data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of 'speech_data.py' file\n",
    "해당 파일은 아직 완벽히 개발이 진행 중인 것으로 보이고, 현재 개발중인 것으로 보입니다.\n",
    "\n",
    "개발은 깃허브 오픈소스로 관리되고 있는 것 같습니다.\n",
    "\n",
    "## 1. import module\n",
    "\n",
    "```python\n",
    "import os  # 경로 및 환경구축을 위해 import한다.\n",
    "           # 예를 들어 압축을 풀려고할 때 해당 디렉토리가 없으면 os.mkdir로 디렉토리 만듦\n",
    "           # os.listdir(path)는 해당 path안에 파일들의 목록을 리스트로 만들어 리턴해준다.\n",
    "import re  # 정규표현식을 위해서 're'라는 모듈을 import한다.\n",
    "           # filepath = os.path.join(work_directory, re.sub('.*\\/','',file))\n",
    "import sys\n",
    "import wave\n",
    "\n",
    "# try-catch문을 통해서 librosa module이 없더라도 실행이 가능하게 해준다.\n",
    "try:\n",
    "\timport librosa\n",
    "    # 음악이나 오디오 파일을 분석할 때 사용하는 패키지이다.\n",
    "    # 'mfcc_batch_geneartor' 사용시에 필요하다.\n",
    "    \n",
    "except:\n",
    "\tprint(\"pip install librosa ; if you want mfcc_batch_generator\")\n",
    "    \n",
    "# shuffle 하기위해 사용하는 module\n",
    "from random import shuffle\n",
    "\n",
    "# try-catch문을 통해서 다음 아래 라이브러리가 없을 때 실행이 가능하게 해준다.\n",
    "try:\n",
    "\tfrom six.moves import urllib\n",
    "\tfrom six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "    # 다음 두개의 라이브러리는 python2와 3에 버전차이를 해결하기위한 module이다.\n",
    "    # 2to3여서 곱하기로 6이되서  'six'라고 함.\n",
    "except:\n",
    "\tpass # fXXX 2to3 : 2to3을 쓰지 않는 경우\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using tensorflow version 1.3.0\n"
     ]
    }
   ],
   "source": [
    "# Simple speaker recognition demo, with 99% accuracy in under a minute ( on digits sample )\n",
    "\n",
    "# | Adam | epoch: 030 | loss: 0.05330 - acc: 0.9966 -- iter: 0000/1000\n",
    "# \u001b'predicted speaker for 9_Vicki_260 : result = ', 'Vicki'\n",
    "import tensorflow as tf\n",
    "print(\"You are using tensorflow version \"+ tf.__version__) #+\" tflearn version \"+ tflearn.version)\n",
    "if tf.__version__ >= '0.12' and os.name == 'nt':\n",
    "\tprint(\"sorry, tflearn is not ported to tensorflow 0.12 on windows yet!(?)\")\n",
    "\t#quit() # why? works on Mac?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for data spoken_numbers_spectros_64x64.tar in data/\n",
      "Extracting data/spoken_numbers_spectros_64x64.tar to data/\n",
      "Data ready!\n",
      "Looking for data spoken_numbers_pcm.tar in data/\n",
      "Extracting data/spoken_numbers_pcm.tar to data/\n",
      "Data ready!\n",
      "15  speakers:  ['Princess', 'Junior', 'Kathy', 'Samantha', 'Ralph', 'Fred', 'Victoria', 'Albert', 'Steffi', 'Daniel', 'Alex', 'Bruce', 'Vicki', 'Tom', 'Agnes']\n",
      "speakers ['Princess', 'Junior', 'Kathy', 'Samantha', 'Ralph', 'Fred', 'Victoria', 'Albert', 'Steffi', 'Daniel', 'Alex', 'Bruce', 'Vicki', 'Tom', 'Agnes']\n",
      "Looking for data spoken_numbers_pcm.tar in data/\n",
      "Extracting data/spoken_numbers_pcm.tar to data/\n",
      "Data ready!\n",
      "Looking for data spoken_numbers_spectros_64x64.tar in data/\n",
      "Extracting data/spoken_numbers_spectros_64x64.tar to data/\n",
      "Data ready!\n",
      "Looking for data spoken_numbers_pcm.tar in data/\n",
      "Extracting data/spoken_numbers_pcm.tar to data/\n",
      "Data ready!\n",
      "15  speakers:  ['Princess', 'Junior', 'Kathy', 'Samantha', 'Ralph', 'Fred', 'Victoria', 'Albert', 'Steffi', 'Daniel', 'Alex', 'Bruce', 'Vicki', 'Tom', 'Agnes']\n",
      "loaded batch of 2402 files\n",
      "loaded batch of 2402 files\n",
      "2402   2402\n"
     ]
    }
   ],
   "source": [
    "speakers = data.get_speakers()\n",
    "number_classes=len(speakers)\n",
    "print(\"speakers\",speakers)\n",
    "\n",
    "batch=data.wave_batch_generator(batch_size=2402, source=data.Source.DIGIT_WAVES, target=data.Target.speaker)\n",
    "X,Y=next(batch)\n",
    "print(len(X), \" \" ,len(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Function\n",
    "### 2.0 0000_ batch_generator\n",
    "batch를 생성해서 만들어주는 함수들이다. speech_data.py에 보면 굉장히 다양한 batch_generator가 있습니다. (spectro, mfcc, wave)\n",
    "\n",
    "그 중 코드에서 사용하고 있는 wave_batch_generator에 대해 설명하겠습니다.\n",
    "\n",
    "### 2.1 wave_batch_generator\n",
    "\n",
    "```python\n",
    "# If you set dynamic_pad=True when calling tf.train.batch \n",
    "# the returned batch will be automatically padded with 0s. Handy! A lower-level option is to use tf.PaddingFIFOQueue.\n",
    "# only apply to a subset of all images at one time\n",
    "\n",
    "def wave_batch_generator(batch_size=10,source=Source.DIGIT_WAVES,target=Target.digits): #speaker\n",
    "\tmaybe_download(source, DATA_DIR)\n",
    "\tif target == Target.speaker: speakers=get_speakers()\n",
    "\tbatch_waves = []\n",
    "\tlabels = []\n",
    "\t# input_width=CHUNK*6 # wow, big!!\n",
    "\t# os.listdir는 해당 path에 모든 파일들의 이름을 리스트에 저장해준다.\n",
    "\tfiles = os.listdir(path)\n",
    "\twhile True:\n",
    "\t\tshuffle(files) #file이름이 들어있는 list를 섞습니다.\n",
    "\t\t# 안에 총 몇개의 파일이 있는지 보여준다.       \n",
    "\t\tprint(\"loaded batch of %d files\" % len(files))\n",
    "\t\tfor wav in files:\n",
    "                \n",
    "\t\t\t# .wav로 끝나는 파일이 아니면 아래의 내용을 실행하지 않는다.\n",
    "\t\t\tif not wav.endswith(\".wav\"):continue\n",
    "                    \n",
    "\t\t\t# wav[0]은 첫번 째 글자임.             \n",
    "\t\t\t# 만약 원하는 target이 Target.digits의 경우에는 파일에 맨첫번째의 int값을 label로 한다==> 이경우 label이 숫자\n",
    "\t\t\t# 즉 여기 걸리는 경우에는 숫자인식을 하기위한 label을 만든다. one hot encoding으로 뒤에 인수가 없으면 \n",
    "            # default=10(0~9)\n",
    "\t\t\tif target==Target.digits: labels.append(dense_to_one_hot(int(wav[0])))\n",
    "                        \n",
    "\t\t\t# 만약 원하는 target이 Target.speaker(화자)의 경우에는 화자의 이름을 label로 하는 one hot encoding을해서 \n",
    "            # labels을 구성\n",
    "\t\t\t# 이경우에는 리턴이 [0, 0, 1, 0 ..... ] 이런식의 데이터            \n",
    "\t\t\telif target==Target.speaker: labels.append(one_hot_from_item(speaker(wav), speakers))\n",
    "                            \n",
    "\t\t\t# ord는 아스키값을 리턴해주는 것 \n",
    "\t\t\t# 32개에서 1한개로 나타낸다 왜 32개인지는 잘 모르겠습니다. 아마 지금은 데이터가 0~9로 10개밖에 없지만\n",
    "\t\t\t# 추후에는 32개의 데이터를 classify할 때 사용하려는 것으로 보임.            \n",
    "\t\t\telif target==Target.first_letter:  label=dense_to_one_hot((ord(wav[0]) - 48) % 32,32)\n",
    "                                \n",
    "            # 현재 미구현 상태                    \n",
    "\t\t\telse: raise Exception(\"todo : Target.word label!\")\n",
    "                                    \n",
    "\t\t\t#chunk의 크기는 (8192)만큼의 크기이다.              \n",
    "\t\t\tchunk = load_wav_file(path+wav)\n",
    "\t\t\tbatch_waves.append(chunk)\n",
    "\t\t\t# batch_waves.append(chunks[input_width])\n",
    "\t\t\t# yeild로 하면 대용량 처리가 가능. 리턴을하고 해당 위치부터 시작.            \n",
    "\t\t\tif len(batch_waves) >= batch_size:\n",
    "\t\t\t\tyield batch_waves, labels\n",
    "\t\t\t\tbatch_waves = []  # Reset for next batch\n",
    "\t\t\t\tlabels = []\n",
    "```\n",
    "### 2.2 load_wav_file\n",
    "\n",
    "```python\n",
    "def load_wav_file(name):\n",
    "\t# 원하는 이름의 파일을 read-only로 연다.\n",
    "\tf = wave.open(name, \"rb\")\n",
    "-\n",
    "\tchunk = []\n",
    "\tdata0 = f.readframes(CHUNK)\n",
    "\twhile data0:  # f.getnframes()\n",
    "\t\t# data = numpy.fromstring(data0, dtype='float32')\n",
    "\t\t# data = numpy.fromstring(data0, dtype='uint16')\n",
    "\t\tdata = numpy.fromstring(data0, dtype='uint8')\n",
    "\t\tdata = (data + 128) / 255.  # 0-1 for Better convergence # 0.5보다 크게 된다.\n",
    "\t\t# chunks.append(data)\n",
    "\t\tchunk.extend(data)\n",
    "\t\tdata0 = f.readframes(CHUNK)\n",
    "\t# finally trim:\n",
    "\tchunk = chunk[0:CHUNK * 2]  # should be enough for now -> cut\n",
    "\tchunk.extend(numpy.zeros(CHUNK * 2 - len(chunk)))  # fill with padding 0's\n",
    "\t# print(\"%s loaded\"%name)\n",
    "\treturn chunk\n",
    "\n",
    "```\n",
    "\n",
    "### 2.3 speaker, get_speaker\n",
    "\n",
    "``` python\n",
    "def speaker(filename):  # vom Dateinamen\n",
    "\t# if not \"_\" in file:\n",
    "\t#   return \"Unknown\"\n",
    "\treturn filename.split(\"_\")[1]\n",
    "```\n",
    "\n",
    "문자열 \"000_XXX_CCC_...\"와 같이 구성됐을때 첫번째 **_** 이후에 글자 XXX를 리턴한다.\n",
    "```python\n",
    "    data.speaker(\"hello_bye_right\")\n",
    "    # 결과 bye\n",
    "```\n",
    "\n",
    "파일의 구성에서 0_Agnes_100과 같이 되어있으므로 Agnes와 같이 해당 소리파일의 화자이름을 리턴한다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# get speaker name from file name '\n",
    "def get_speakers(path=pcm_path):\n",
    "\tmaybe_download(Source.DIGIT_SPECTROS)\n",
    "\tmaybe_download(Source.DIGIT_WAVES)\n",
    "\tfiles = os.listdir(path)\n",
    "\tdef nobad(name):\n",
    "\t\treturn \"_\" in name and not \".\" in name.split(\"_\")[1]\n",
    "\tspeakers=list(set(map(speaker,filter(nobad,files))))\n",
    "\tprint(len(speakers),\" speakers: \",speakers)\n",
    "\treturn speakers\n",
    "```\n",
    "\n",
    "해당 디렉토리에 있는 파일들을 스캔하면서 화자 15명을 찾아 리스트로 만들어주는 함수이다.\n",
    "\n",
    "결과적으로\n",
    "\n",
    "**['Daniel', 'Alex', 'Victoria', 'Vicki', 'Junior', 'Kathy', 'Albert', 'Fred', 'Ralph', 'Tom', 'Samantha', 'Agnes', 'Bruce', 'Princess', 'Steffi']**\n",
    "\n",
    "값을 리턴해줍니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 maybe_download\n",
    "\n",
    "```python\n",
    "def maybe_download(filename, work_directory, source_url):\n",
    "  \"\"\"Download the data from source url, unless it's already here.\n",
    "  Args:\n",
    "      filename: string, name of the file in the directory.\n",
    "      work_directory: string, path to working directory.\n",
    "      source_url: url to download from if file doesn't exist.\n",
    "  Returns:\n",
    "      Path to resulting file.\n",
    "  \"\"\"\n",
    "  if not gfile.Exists(work_directory):\n",
    "    gfile.MakeDirs(work_directory)\n",
    "  filepath = os.path.join(work_directory, filename)\n",
    "  if not gfile.Exists(filepath):\n",
    "    temp_file_name, _ = urlretrieve_with_retry(source_url)\n",
    "    gfile.Copy(temp_file_name, filepath)\n",
    "    with gfile.GFile(filepath) as f:\n",
    "      size = f.size()\n",
    "    print('Successfully downloaded', filename, size, 'bytes.')\n",
    "  return filepath\n",
    "```\n",
    "함수 이름처럼 만약 해당 파일이 있으면 다운받지 않고 없는 경우에는 url로부터 다운받는다.\n",
    "\n",
    "인수로는 1. 파일이름, 2. 디렉토리, 3. 다운받고하자는 url주소.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<세부 설명>\n",
    "    \n",
    "    data/라는 directory가 있는지 확인한 후, data/라는 directory가 없다면 만들어준다.\n",
    "\n",
    "    filepath = data/Source.DIGIT_WAVES 가 존재하는지 확인한다\n",
    "\n",
    " \n",
    "\n",
    "    1. filepath = data/Source.DIGIT_WAVES 가 존재하지 않을 때,\n",
    "\n",
    "        data/Source.DIGIT_WAVES 에 \"http\"로 시작하는 파일이 없다면, \n",
    "\n",
    "        url_filename이라는 변수를 http://pannous.net/files/Source.DIGIT_WAVES 로 설정해준다.\n",
    "\n",
    "        이미 있다면,\n",
    "\n",
    "        url_filename이라는 변수를 Source.DIGIT_WAVES로 설정해준다.\n",
    "\n",
    " \n",
    "\n",
    "        http://pannous.net/files/Source.DIGIT_WAVES에 해당하는 파일을\n",
    "\n",
    "        data/Source.DIGIT_WAVES에 저장한다.\n",
    "\n",
    " \n",
    "\n",
    "        'Successfully downloaded 파일이름, 데이터 용량'을 print한다.\n",
    "\n",
    " \n",
    "\n",
    "    2. filepath = data/Source.DIGIT_WAVES 가 존재할 때,\n",
    "\n",
    "        'Extracting data/Source.DIGIT_WAVES to 경로'\n",
    "\n",
    "        'Data ready!'를 print."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2.5 변수관리 클래스(Source, Target)\n",
    "\n",
    "``` python\n",
    "\n",
    "# TRAIN_INDEX='train_words_index.txt'\n",
    "# TEST_INDEX='test_words_index.txt'\n",
    "SOURCE_URL = 'http://pannous.net/files/' #spoken_numbers.tar'\n",
    "DATA_DIR = 'data/'\n",
    "pcm_path = \"data/spoken_numbers_pcm/\" # 8 bit\n",
    "wav_path = \"data/spoken_numbers_wav/\" # 16 bit s16le\n",
    "path = pcm_path\n",
    "CHUNK = 4096\n",
    "test_fraction=0.1 # 10% of data for test / verification\n",
    "\n",
    "# http://pannous.net/files/spoken_numbers_pcm.tar\n",
    "class Source:  # labels\n",
    "\tDIGIT_WAVES = 'spoken_numbers_pcm.tar'\n",
    "\tDIGIT_SPECTROS = 'spoken_numbers_spectros_64x64.tar'  # 64x64  baby data set, works astonishingly well\n",
    "\tNUMBER_WAVES = 'spoken_numbers_wav.tar'\n",
    "\tNUMBER_IMAGES = 'spoken_numbers.tar'  # width=256 height=256\n",
    "\tWORD_SPECTROS = 'https://dl.dropboxusercontent.com/u/23615316/spoken_words.tar'  # width,height=512# todo: sliding window!\n",
    "\tWORD_WAVES = 'spoken_words_wav.tar'\n",
    "\tTEST_INDEX = 'test_index.txt'\n",
    "\tTRAIN_INDEX = 'train_index.txt'\n",
    "from enum import Enum\n",
    "#원하는 Target에 대한 정보를 갖는다.\n",
    "class Target(Enum):  # labels\n",
    "\tdigits=1\n",
    "\tspeaker=2\n",
    "\twords_per_minute=3\n",
    "\tword_phonemes=4\n",
    "\tword = 5  # int vector as opposed to binary hotword\n",
    "\tsentence=6\n",
    "\tsentiment=7\n",
    "\tfirst_letter=8\n",
    "\thotword = 9\n",
    "\t# test_word=9 # use 5 even for speaker etc\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cf.\"__main__\"\n",
    "\n",
    "```python\n",
    "if __name__ == \"__main__\":\n",
    "\tprint(\"downloading speech datasets\")\n",
    "\tmaybe_download( Source.DIGIT_SPECTROS)\n",
    "\tmaybe_download( Source.DIGIT_WAVES)\n",
    "\tmaybe_download( Source.NUMBER_IMAGES)\n",
    "\tmaybe_download( Source.NUMBER_WAVES)\n",
    "\n",
    "```\n",
    "만약 해당 .py파일이 main으로 사용됐을 경우 실행되는 코드 부분입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cf. yield 설명\n",
    "\n",
    "```python\n",
    "def gen():\n",
    "    yield 'one'\n",
    "    yield 'two'\n",
    "    yield 'three'\n",
    "\n",
    "g = gen()\n",
    "print(next(g))  # one\n",
    "print(next(g))  # two\n",
    "print(next(g))  # three\n",
    "print(next(g))  # raise StopIteration\n",
    "```\n",
    "yield는 함수 실행 중간에 빠져나올 수 있는 generator를 만들 때 사용합니다.\n",
    "return이었다면 'one'이 반환되고 끝났겠지만 실제로는 그 뒤로도 다시 사용할 수 있습니다.\n",
    "yield는 단순히 값을 내보낼 수만 있는 것은 아니고, 넣어줄 수도 있습니다.\n",
    "\n",
    "```python\n",
    "def gen():\n",
    "    val = 111111\n",
    "    while True:\n",
    "        val = (yield val) * 111111\n",
    "\n",
    "g = gen()\n",
    "print(next(g))  # 111111\n",
    "print(g.send(2))  # 2를 보냅니다 결국 2*111111==결과 : 222222\n",
    "print(g.send(3))  # 3을 보냅니다 결국 3*111111==결과 : 333333\n",
    "```\n",
    "위에서도 언급했지만 대용량 자료 처리등은 메모리에 모두 올려놓고 할 수 없습니다.\n",
    "그런 경우 한 줄씩 읽은 뒤 generator를 이용한 반복처리를 하면 편합니다.\n",
    "실제로도 Flask에서의 대용량 파일 전송, Sphinx의 확장 개발등에 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train # :  1921\n",
      "Test  # :  481\n"
     ]
    }
   ],
   "source": [
    "training_number = int(2402*0.8)\n",
    "x_train = X[0:training_number]\n",
    "y_train = Y[0:training_number]\n",
    "x_test = X[training_number:]\n",
    "y_test = Y[training_number:]\n",
    "print(\"Train # : \",training_number)\n",
    "print(\"Test  # : \", 2402-training_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3099  | total loss: \u001b[1m\u001b[32m0.01399\u001b[0m\u001b[0m | time: 0.639s\n",
      "| Adam | epoch: 100 | loss: 0.01399 - acc: 0.9981 -- iter: 1920/1921\n",
      "Training Step: 3100  | total loss: \u001b[1m\u001b[32m0.01409\u001b[0m\u001b[0m | time: 0.659s\n",
      "| Adam | epoch: 100 | loss: 0.01409 - acc: 0.9983 -- iter: 1921/1921\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Original code need to be changed to tensorflow code\n",
    "# Classification\n",
    "tflearn.init_graph(num_cores=8, gpu_memory_fraction=0.5)\n",
    "\n",
    "net = tflearn.input_data(shape=[None, 8192]) #Two wave chunks each wave has 4096\n",
    "net = tflearn.fully_connected(net, 64)\n",
    "net = tflearn.dropout(net, 0.5)\n",
    "net = tflearn.fully_connected(net, number_classes, activation='softmax')\n",
    "net = tflearn.regression(net, optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=3, tensorboard_dir=\"logs\")\n",
    "model.fit(x_train, y_train, n_epoch=100, show_metric=True, snapshot_step=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < result  >  n_epoch=100\n",
    "Training Step: 3099  | total loss: 0.01399 | time: 0.639s\n",
    "\n",
    "| Adam | epoch: 100 | loss: 0.01399 - acc: 0.9981 -- iter: 1920/1921\n",
    "\n",
    "Training Step: 3100  | total loss: 0.01409 | time: 0.659s\n",
    "\n",
    "| Adam | epoch: 100 | loss: 0.01409 - acc: 0.9983 -- iter: 1921/1921"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy graph (graph by tensorboard)\n",
    "\n",
    "<img src=\"acc.PNG\" style=\"width: 800px;\">\n",
    "\n",
    "### loss graph (graph by tensorboard)\n",
    "\n",
    "<img src=\"loss.PNG\" style=\"width: 800px;\">\n",
    "\n",
    "### Architecture (graph by  tensorboard)\n",
    "\n",
    "<img src=\"architect.png\" style=\"width: 800px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test data &  total train data accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data number :  481\n",
      "test accuracy :  0.40332640332640335\n",
      "total train data accuracy :  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"test data number : \",len(x_test))\n",
    "k =  model.predict(x_test)\n",
    "cnt = 0\n",
    "for i in range(481):\n",
    "    predict = k[i].argmax()\n",
    "    real = np.array(y_test[i]).argmax()\n",
    "    if(predict==real):\n",
    "        cnt+=1\n",
    "tst_accuracy = cnt/481.0\n",
    "print(\"test accuracy : \", tst_accuracy)\n",
    "\n",
    "t =  model.predict(x_train)\n",
    "cnt2 = 0\n",
    "for i in range(1921):\n",
    "    predict = t[i].argmax()\n",
    "    real = np.array(y_train[i]).argmax()\n",
    "    if(predict==real):\n",
    "        cnt2+=1\n",
    "print(\"total train data accuracy : \",cnt2/1921.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total data 2402 num .wav file accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data number :  2402\n",
      "total data accuracy :  0.8805162364696086\n"
     ]
    }
   ],
   "source": [
    "print(\"total data number : \",len(X))\n",
    "k =  model.predict(X)\n",
    "\n",
    "cnt = 0\n",
    "for i in range(2402):\n",
    "    predict = k[i].argmax()\n",
    "    real = np.array(Y[i]).argmax()\n",
    "    if(predict==real):\n",
    "        cnt+=1\n",
    "\n",
    "tot_accuracy = cnt/2402\n",
    "print(\"total data accuracy : \", tot_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < result  >  model test data accuracy\n",
    "\n",
    "test data number :  481, train data number : 1921, total data number : 2402\n",
    "\n",
    "test accuracy :  0.40332640332640335\n",
    "\n",
    "train data accuracy :  1.0\n",
    "\n",
    "total data accuracy : 0.8805162364696086"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test on specific data\n",
    "\n",
    "특정한 데이터 \"8_Vicki_260.wav\", \"8_Bruce_260.wav\"두 데이터에 대한 테스트를 진행했을 때의 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted speaker for 8_Vicki_260.wav : result = Vicki \n",
      "predicted speaker for 8_Bruce_260.wav : result = Bruce \n"
     ]
    }
   ],
   "source": [
    "# 파일이름과 data.path를 이용해서 load\n",
    "demo_file = \"8_Vicki_260.wav\"\n",
    "demo_file2 = \"8_Bruce_260.wav\"\n",
    "demo=data.load_wav_file(data.path + demo_file)\n",
    "demo2=data.load_wav_file(data.path + demo_file2)\n",
    "\n",
    "\n",
    "result=model.predict([demo])\n",
    "result2=model.predict([demo2])\n",
    "result=data.one_hot_to_item(result,speakers)\n",
    "result2=data.one_hot_to_item(result2,speakers)\n",
    "print(\"predicted speaker for %s : result = %s \"%(demo_file,result))\n",
    "print(\"predicted speaker for %s : result = %s \"%(demo_file2,result2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
