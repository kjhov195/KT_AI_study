{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim Dimension = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ktai18/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/ktai18/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import movie_reviews\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('movie_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.'], ['they', 'get', 'into', 'an', 'accident', '.'], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = movie_reviews.sents()\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71532 <class 'nltk.corpus.reader.util.ConcatenatedCorpusView'>\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences), type(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.ConcatenatedCorpusView'>\n",
      "<class 'list'>\n",
      "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party', ',', 'drink', 'and', 'then', 'drive', '.']\n",
      "['they', 'get', 'into', 'an', 'accident', '.']\n",
      "['one', 'of', 'the', 'guys', 'dies', ',', 'but', 'his', 'girlfriend', 'continues', 'to', 'see', 'him', 'in', 'her', 'life', ',', 'and', 'has', 'nightmares', '.']\n",
      "['what', \"'\", 's', 'the', 'deal', '?']\n",
      "['watch', 'the', 'movie', 'and', '\"', 'sorta', '\"', 'find', 'out', '.']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(type(sentences))\n",
    "sentences = list(sentences)\n",
    "print(type(sentences))\n",
    "for i in range(5):\n",
    "    print(sentences[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word2vec on the two sentences\n",
    "model = Word2Vec(sentences, size=3, min_count=1 ,iter=100, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 특정단어의 vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take :  [-1.764611   1.4263136 -1.1780676]\n",
      "stroy :  [-1.4661554  2.4752538  2.5391748]\n",
      "her :  [ 0.78013945  0.00340516 -3.1281555 ]\n",
      "film :  [-2.8288817  3.0535293  2.5445015]\n",
      "make :  [-4.654068    2.9117815  -0.23030926]\n",
      "good :  [-3.5191054   2.5680041  -0.23583286]\n",
      "storyline :  [-1.6047614  3.0119662  3.7457945]\n",
      "he :  [-2.6598477  1.3556339 -3.2764487]\n",
      "keep :  [-2.1678145   1.5810946  -0.96156687]\n"
     ]
    }
   ],
   "source": [
    "print('take : ' , model.wv['take'])\n",
    "print('stroy : ' ,model.wv['story'])\n",
    "print('her : ' ,model.wv['her'])\n",
    "print('film : ' ,model.wv['film'])\n",
    "print('make : ' ,model.wv['make'])\n",
    "print('good : ' ,model.wv['good'])\n",
    "print('storyline : ' ,model.wv['storyline'])\n",
    "print('he : ' ,model.wv['he'])\n",
    "print('keep : ' ,model.wv['keep'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 특정단어와 유사한 vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the :  ['the', 'stance', 'elegance', 'ethics', 'equality', 'texture', 'incomprehensibly', 'proficiency', 'overlapping', 'complications']\n",
      "\n",
      "movie :  ['movie', 'soundbite', 'worth', 'bit', 'generate', 'plausible', 'far', 'profound', 'momentum', 'importantly']\n",
      "\n",
      "plot :  ['plot', 'text', 'spoilers', 'inducing', 'jokes', 'conclusion', 'pacing', 'portions', 'qualities', 'times']\n",
      "\n",
      "simple :  ['simple', 'attention', 'miserably', 'explored', 'evident', 'boast', 'tricky', 'serve', 'shred', 'absurdly']\n",
      "\n",
      "she :  ['she', 'breillat', 'lest', 'dosen', 'asking', 'painless', 'castor', 'stephane', 'exorcise', 'help']\n",
      "\n",
      "spend :  ['spend', 'excesses', 'godzillas', 'explanation', 'word', 'sufficient', 'particulars', 'surely', 'excruciatingly', 'apparent']\n",
      "\n",
      "time :  ['time', 'sublime', 'richness', 'metro', 'fanatasies', 'contrary', 'awful', 'end', 'making', 'meaning']\n",
      "\n",
      "with :  ['with', 'weighs', 'update', 'distortion', 'naturalistic', 'sunken', 'intruder', 'titanic', 'coppolas', 'descended']\n",
      "\n",
      "him :  ['him', 'triumphed', 'ix', 'exorcise', 'decide', 'qualified', 'mariah', '_dragonheart_', 'stephane', 'help']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sec_list = ['the','movie','plot','simple','she','spend','time','with','him']\n",
    "for it in range(len(sec_list)):\n",
    "    words_list = []\n",
    "    k = model.wv.similar_by_vector(model.wv[sec_list[it]])\n",
    "    for i in range(10):\n",
    "        words_list.append(k[i][0])\n",
    "    print(sec_list[it], ': ', words_list)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 최고 유사도 단어 3개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the > [0.40661427 1.3279345  1.4280571 ]\n",
      "stance      vector: [0.40569237 1.3263762  1.4144838 ]\n",
      "elegance      vector: [0.20599964 0.6891275  0.73183   ]\n",
      "ethics      vector: [0.53771096 1.6808861  1.8567756 ]\n",
      "\n",
      "movie > [-3.6630096  3.3164032  2.1379886]\n",
      "soundbite      vector: [-0.40374532  0.3675178   0.23868406]\n",
      "worth      vector: [-3.4395943  3.1613307  2.0411303]\n",
      "bit      vector: [-3.416448   3.0450606  1.9323546]\n",
      "\n",
      "plot > [-4.313104   4.5125666  4.9398174]\n",
      "text      vector: [-4.897897   5.3236446  5.8910184]\n",
      "spoilers      vector: [-4.697869  5.067164  5.271859]\n",
      "inducing      vector: [-2.4937062  2.7277772  3.0141115]\n",
      "\n",
      "simple > [-2.1390119  2.3677647  1.2469342]\n",
      "attention      vector: [-2.0001414  2.227163   1.165757 ]\n",
      "miserably      vector: [-2.470116   2.7798128  1.4921438]\n",
      "explored      vector: [-2.083647   2.348483   1.2690673]\n",
      "\n",
      "she > [-2.8809254  1.2239282 -4.425476 ]\n",
      "breillat      vector: [-1.1528822  0.5045699 -1.7547616]\n",
      "lest      vector: [-1.7072642  0.7277499 -2.5739012]\n",
      "dosen      vector: [-2.4462519  1.0872406 -3.739938 ]\n",
      "\n",
      "spend > [-2.1652231  2.1215818  0.44772  ]\n",
      "excesses      vector: [-0.84470147  0.8242113   0.1698794 ]\n",
      "godzillas      vector: [-1.13947     1.1311893   0.23867379]\n",
      "explanation      vector: [-2.706335   2.6460927  0.5988564]\n",
      "\n",
      "time > [-1.5932605  2.1679735  1.1602407]\n",
      "sublime      vector: [-1.466555   1.9752891  1.0781702]\n",
      "richness      vector: [-1.8223598  2.4463015  1.3457049]\n",
      "metro      vector: [-1.7761872  2.464618   1.3329095]\n",
      "\n",
      "with > [1.0911702  0.77539575 0.8468944 ]\n",
      "weighs      vector: [2.0435767 1.4259372 1.5714432]\n",
      "update      vector: [1.6256522 1.1364881 1.2850022]\n",
      "distortion      vector: [1.2889359 0.9094945 1.0277961]\n",
      "\n",
      "him > [-1.7469846  0.9514033 -3.2086234]\n",
      "triumphed      vector: [-0.6210079   0.34125838 -1.1306117 ]\n",
      "ix      vector: [-0.44524553  0.2533601  -0.7916224 ]\n",
      "exorcise      vector: [-0.8491929  0.3949239 -1.444626 ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sec_list = ['the','movie','plot','simple','she','spend','time','with','him']\n",
    "for i in range(len(sec_list)):\n",
    "    a = model.wv.similar_by_vector(sec_list[i])\n",
    "    print(sec_list[i], \">\", model.wv[sec_list[i]])\n",
    "    for j in range(3):\n",
    "        print(a[j][0], '     vector:', model.wv[a[j][0]])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 단어 간의 상관관계 출력 (woman:man = ?:king)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chow', 0.9999681115150452),\n",
       " ('addict', 0.9999614953994751),\n",
       " ('diggs', 0.9999577403068542)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['king', 'man'], negative=['woman'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 의미를 가지는 단어 쌍 (woman:man = queen:king) 2개 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', 'a', 'church', 'party']\n"
     ]
    }
   ],
   "source": [
    "sentences_w = movie_reviews.words()\n",
    "print(sentences_w[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1583820\n",
      "<class 'nltk.corpus.reader.util.ConcatenatedCorpusView'>\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences_w))\n",
    "print(type(sentences_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_k=set(sentences_w)\n",
    "sentences_k=list(sentences_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ruses', 'assed', 'jackets', 'diary', 'theorems', 'tome', 'north', 'categories', 'madeleine', 'rekall']\n"
     ]
    }
   ],
   "source": [
    "num=len(sentences_k)\n",
    "num\n",
    "print(sentences_k[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9984668672154628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim1=model.wv.similarity('woman','man')\n",
    "sim1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998200290523023"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim2=model.wv.similarity('queen','king')\n",
    "sim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991434481338826"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim3=(sim1+sim2)/2\n",
    "sim3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count=0\n",
    "det = 1\n",
    "\n",
    "val_list=[]\n",
    "word_list=[]\n",
    "\n",
    "lo = sim3*0.99999\n",
    "hi = sim3*1.00001\n",
    "\n",
    "\n",
    "for i in range(num):\n",
    "    v1=sentences_k[i]\n",
    "    for j in range(num):\n",
    "        \n",
    "        v2=sentences_k[j]\n",
    "        value=model.wv.similarity(v1,v2)\n",
    "\n",
    "        if lo<value<hi:\n",
    "#            print(\"i:\"+str(i)+\", j:\"+str(j))\n",
    "            count +=1\n",
    "            val_list.append(value)\n",
    "            word_list.append(v1)\n",
    "            word_list.append(v2)\n",
    "            break\n",
    "        if count==2:\n",
    "            det = 0\n",
    "            break\n",
    "    if det==0:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.999146164911622, 0.9991451468236978]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ruses', 'catchphrases', 'assed', 'maximal']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
